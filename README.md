# Machine Learning Algorithm - Decision Trees

### Basic Assumption of Decision Tree
There are no such assumptions.

### Advantages of Decision Tree
1. Clear Visualization: The algorithm is simple to understand, interpret and
visualize as the idea is mostly used in our daily lives. Output of a Decision
Tree can be easily interpreted by humans.
2. Simple and easy to understand: Decision Tree looks like simple if-else state-
ments which are very easy to understand.
3. Decision Tree can be used for both classification and regression problems.
4. Decision Tree can handle both continuous and categorical variables.
5. No feature scaling required: No feature scaling (standardization and nor-
malization) required in case of Decision Tree as it uses rule based approach
instead of distance calculation.
6. Handles non-linear parameters efficiently: Non linear parameters donâ€™t affect
the performance of a Decision Tree unlike curve based algorithms. So, if there
is high non-linearity between the independent variables, Decision Trees may
outperform as compared to other curve based algorithms.
7. Decision Tree can automatically handle missing values.
8. Decision Tree is usually robust to outliers and can handle them automatically.
9. Less Training Period: Training period is less as compared to Random Forest
because it generates only one tree unlike forest of trees in the Random Forest.
